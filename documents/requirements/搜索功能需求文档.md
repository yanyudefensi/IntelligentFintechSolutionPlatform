## 搜索返回内容
用户输入搜索条件点击搜索后需求返回以下内容：  
<table>
<tr>
<th>百科</th>
<th>解决方案</th>
<th>技术文章</th>
<th>服务提供商</th>
<th>知识图谱</th>
</tr>
</table>  


> 1、百科  

五大关键词对应五个百科，将用户输入的查询条件对应到五个百科中的  
一个，将对应的百科信息返回，百科应包含以下内容：  
（1）给出一个关键词相关的结构框图  
创建2-3个知识层次，以人工智能为例，有几个二级分类：  
1）有监督、无监督学习、半监督、强化学习  
2）数值/纹理分类、数值回归  
3）NLP、TTS/STT、计算机视觉等  
（2）给出一个列表，表项是上面列出的二级分类，每个分类点进去是  
对技术的解释。  

> 2、解决方案  

给出一个解决方案的列表，示例如下：  
<table>
<tr>
<td>全行数据中台<br>提供从基础云架构大数据平台、数据上云、数仓建设、应用集市建设到业务应用等一整套端到端银行大数据中台解决方案。</td>
</tr>
<tr>
<td>原创 | 王欣：多维深耕打造数字化银行<br>我国正加速步入数字化社会，大数据、云计算、人工智能和物联网等新技术浪潮，对银行业固有经营理念和服务模式，乃至对金融生态和竞争格局都带来巨大冲击。西安银行运用“大、智、移、云”技术（大数据</td>
</tr>
</table>  

点击条目跳转到第三方网站解决方案的页面。  

> 3、服务提供商  

给出一个服务提供商列表，点击其中任何一个服务提供商，跳转到提供商  
的介绍页面，服务提供商总体需要至少包含fintech公司，但是针对用户  
具体的某一次搜索我们只返回跟用户此次搜索相关的提供商。  

> 4、技术文章  

给出一个技术文章列表，点击其中一项，跳转到第三方网站详情页。  

> 5、知识图谱  

根据用户输入的搜索条件，返回一个相关内容的知识图谱，图谱形式  
类似于neo4j数据节点和节点关系查询后返回的图形结果。  

## 爬虫相关内容
> 1、语料规模  

语料总规模36G，各大关键词占比如下（根据要求文件相关内容）：  
<table>
<tr>
<th>关键词</th>
<th>语料规模</th>
<th>备注</th>
</tr>
<tr>
<td>人工智能</td>
<td>约10G</td>
<td>与领域相关短语至少200个，解决方案至少60个</td>
</tr>
<tr>
<td>区块链</td>
<td>约10G</td>
<td>与领域相关短语至少200个，解决方案至少60个</td>
</tr>
<tr>
<td>物联网</td>
<td>约5G</td>
<td>与领域相关短语至少30个，解决方案至少10个</td>
</tr>
<tr>
<td>云</td>
<td>约5G</td>
<td>与领域相关短语至少30个，解决方案至少10个</td>
</tr>
<tr>
<td>大数据</td>
<td>约5G</td>
<td>与领域相关短语至少30个，解决方案至少10个</td>
</tr>
</table>  

> 2、语料数据结构  

爬取的语料存储为jsonline格式，json具体结构如下：  
```angular2html
{
  type: 'int', // 类型，取值为1、2、3中的一个：解决方案(1)、技术文章(2)、供应商介绍(3)
  url: 'str', // 存储爬取的页面的url
  title: 'str', // 内容标题
  summary: 'str', // 内容概要
  content: 'str', // 爬取的网页全文
  vendor: 'vendor' // 这个字段针对解决方案，保存解决方案对应的服务提供商
}
```

> 3、成员分工  

数据总量是36G，所以3个爬虫工程师每人爬12G数据，两周内完成，不然  
nlp没法进展，项目就会停滞  
爬取网站分配  
<table>
<tr>
<td>范远聪</td>
<td>finetech100的第1-33家公司、CSDN、思否、http://www.itpub.net/</td>
</tr>
<tr>
<td>陈振贤</td>
<td>finetech100的第34-66家公司、开源中国、51CTO、掘金网</td>
</tr>
<tr>
<td>李马可</td>
<td>finetech100的第67-100家公司、开发者头条、异步社区文章版面</td>
</tr>
</table>  

每个人做一张excel表格记录自己的工作进度，表格两列，一列是网站名称  
和网址，另一列是爬取情况，包括爬取是否成功、爬下来多少数据。  
每周给我看一次。
