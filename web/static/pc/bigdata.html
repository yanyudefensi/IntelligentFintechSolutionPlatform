<!DOCTYPE html>
<html lang="en">
<!--这里导入的是高级搜索的header-->

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <link rel="stylesheet" type="text/css" href="/static/css/infinite-slide.css">
  <title>Big Data</title>
  <link rel="stylesheet" href="/static/resource/bootstrap/bootstrap.3.7.css">

  <!--导入jq库-->
  <script src="/static/resource/jquery/jquery.2.1.1.min.js"></script>
  <!--导入javascript-->
  <script src="/static/resource/bootstrap/bootstrap.3.7.js"></script>

  <title>大数据</title>

</head>

<body>

  <!--header的部分-->
  <section>
    <div class="row">
      <div class="col-md-12">
        <div
          style="background: 100% 100% cover no-repeat; height:340px;background-image:url(/static/img/6ab3473504ea6ce0c77e5cd41c355f9.png)">
          <nav class="navbar nav-pills">
            <a href="index.html" class="navbar-brand" style="font-size:18px;color:#FFFFFF">Home</a>
            <a href="kg.html" class="navbar-brand" style="font-size:18px;color:#FFFFFF">KnowledgeGraph</a>
          </nav>
          <section class="Search-box">
            <!--搜索主题-->
            <!--页面主题-->
            <!--页面主题-->
            <section class="Search Title">
              <!--这里也尚未做css文件-->
              <div class="container">
                <!--Search图标-->
                <div class="columns large-12 medium-12 small-12 ">
                  <div class="off-canvas-wrap" data-offcanvas="">
                    <div class="row">
                      <!-- START CONTENT -->
                      <div class="columns large- small-12">
                        <section class="row">
                          <div class="columns small-12">
                            <div class="row tag-page ">
                              <div class="columns small-12">
                                <div class="tag-title_main">
                                  <div class="cat-title_main ">
                                    <h2 style="font-size:28px; color:#FFFFFF"><strong>DICTIONARY</strong></h2>
                                    <hr>
                                  </div>
                                </div>
                              </div>
                            </div>
                          </div>
                        </section>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </section>
          </section>
        </div>
      </div>
    </div>
  </section>




  <div id="wiki-banner" class="wiki-content">

    <!--主要内容开始-->
    <main role="main" aria-labelledby="inf-pagetitle-h1">
      <div data-spy="scroll" data-target="#myScrollspy">
        <div class="container">
          <div class="row">
            <div class="col-xs-3" id="myScrollspy">
              <ul class="nav nac-tabs nav-stacked" data-spy="affix" data-offset-top="125">
                <li class="active"><a href="#section1">Definition</a></li>
                <li class="active"><a href="#section2">Explanations </a></li>
                <li class="active"><a href="#section3">Architecture</a></li>

              </ul>
            </div>
            <div class="col-xs-9">
              <div id="wiki-banner" class="wiki-jumbotron">
                <!--jumbotron是Bootstrap的大标题-->
                <h1>Big Data</h1>
              </div>
              <h3 id="section1">Definition - What does Big Data mean?</h3>
              <!--这个右边的介绍内容-->
              <p>Big data refers to a process that is used when traditional data mining and handling techniques cannot
                uncover the insights and meaning of the underlying data. Data that is unstructured or time sensitive or
                simply very large cannot be processed by relational database engines. This type of data requires a
                different processing approach called big data, which uses massive parallelism on readily-available
                hardware. </p>
              <h3 id="section2">Explanation of Big Data</h3>
              <p>Quite simply, big data reflects the changing world we live in. The more things change, the more the
                changes are captured and recorded as data. Take weather as an example. For a weather forecaster, the
                amount of data collected around the world about local conditions is substantial. Logically, it would
                make sense that local environments dictate regional effects and regional effects dictate global effects,
                but it could well be the other way around. One way or another, this weather data reflects the attributes
                of big data, where real-time processing is needed for a massive amount of data, and where the large
                number of inputs can be machine generated, personal observations or outside forces like sun spots. </p>
              <p> Processing information like this illustrates why big data has become so important:</p>
              <p> • &nbsp; Most data collected now is unstructured and requires different storage and processing than
                that found in &nbsp; &nbsp; &nbsp; traditional relational databases. </p>
              <p> • &nbsp; &nbsp;Available computational power is sky-rocketing, meaning there are more opportunities to
                process big &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;data. </p>
              <p> • &nbsp; &nbsp;The Internet has democratized data, steadily increasing the data available while also
                producing more &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and more raw data.</p>

              <p>
                <p> Data in its raw form has no value. Data needs to be processed in order to be of valuable. However,
                  herein lies the inherent problem of big data. Is processing data from native object format to a usable
                  insight worth the massive capital cost of doing so? Or is there just too much data with unknown values
                  to justify the gamble of processing it with big data tools? Most of us would agree that being able to
                  predict the weather would have value, the question is whether that value could outweigh the costs of
                  crunching all the real-time data into a weather report that could be counted on.</p>
                <p>Machine perception deals with the capability to use sensory inputs to deduce the different aspects of
                  the world,
                  while computer vision is the power to analyze visual inputs with a few sub-problems such as facial,
                  object and gesture recognition.</p>
                <p>Robotics is also a major field related to AI. Robots require intelligence to handle tasks such
                  as object manipulation and navigation, along with sub-problems of localization, motion planning and
                  mapping.</p>
                <h3 id="section3">Architecture</h3>
                <p>Big data repositories have existed in many forms, often built by corporations with a special need.
                  Commercial vendors historically offered parallel database management systems for big data beginning in
                  the 1990s. For many years, WinterCorp published a largest database report. </p>
                <p>Teradata Corporation in 1984 marketed the parallel processing DBC 1012 system. Teradata systems were
                  the first to store and analyze 1 terabyte of data in 1992. Hard disk drives were 2.5 GB in 1991 so the
                  definition of big data continuously evolves according to Kryder's Law. Teradata installed the first
                  petabyte class RDBMS based system in 2007. As of 2017, there are a few dozen petabyte class Teradata
                  relational databases installed, the largest of which exceeds 50 PB. Systems up until 2008 were 100%
                  structured relational data. Since then, Teradata has added unstructured data types including XML,
                  JSON, and Avro. In 2000, Seisint Inc. (now LexisNexis Group) developed a C++-based distributed
                  file-sharing framework for data storage and query. The system stores and distributes structured,
                  semi-structured, and unstructured data across multiple servers. Users can build queries in a C++
                  dialect called ECL. ECL uses an "apply schema on read" method to infer the structure of stored data
                  when it is queried, instead of when it is stored. In 2004, LexisNexis acquired Seisint Inc.[44] and in
                  2008 acquired ChoicePoint, Inc.[45] and their high-speed parallel processing platform. The two
                  platforms were merged into HPCC (or High-Performance Computing Cluster) Systems and in 2011, HPCC was
                  open-sourced under the Apache v2.0 License. Quantcast File System was available about the same
                  time.[46] CERN and other physics experiments have collected big data sets for many decades, usually
                  analyzed via high performance computing (supercomputers) rather than the commodity map-reduce
                  architectures usually meant by the current "big data" movement. In 2004, Google published a paper on a
                  process called MapReduce that uses a similar architecture. The MapReduce concept provides a parallel
                  processing model, and an associated implementation was released to process huge amounts of data. With
                  MapReduce, queries are split and distributed across parallel nodes and processed in parallel (the Map
                  step). The results are then gathered and delivered (the Reduce step). The framework was very
                  successful,[47] so others wanted to replicate the algorithm. Therefore, an implementation of the
                  MapReduce framework was adopted by an Apache open-source project named Hadoop.[48] Apache Spark was
                  developed in 2012 in response to limitations in the MapReduce paradigm, as it adds the ability to set
                  up many operations (not just map followed by reduce). MIKE2.0 is an open approach to information
                  management that acknowledges the need for revisions due to big data implications identified in an
                  article titled "Big Data Solution Offering".[49] The methodology addresses handling big data in terms
                  of useful permutations of data sources, complexity in interrelationships, and difficulty in deleting
                  (or modifying) individual records.[50] 2012 studies showed that a multiple-layer architecture is one
                  option to address the issues that big data presents. A distributed parallel architecture distributes
                  data across multiple servers; these parallel execution environments can dramatically improve data
                  processing speeds. This type of architecture inserts data into a parallel DBMS, which implements the
                  use of MapReduce and Hadoop frameworks. This type of framework looks to make the processing power
                  transparent to the end user by using a front-end application server.[51] The data lake allows an
                  organization to shift its focus from centralized control to a shared model to respond to the changing
                  dynamics of information management. This enables quick segregation of data into the data lake, thereby
                  reducing the overhead time.[52][53] Big data analytics for manufacturing applications is marketed as a
                  "5C architecture" (connection, conversion, cyber, cognition, and configuration).[54]Factory work and
                  Cyber-physical systems may have an extended "6C system": </p>
                <p>• Connection (sensor and networks)</p>
                <p>• Cloud (computing and data on demand)[55][56] </p>
                <p>• Cyber (model and memory) </p>
                <p>• Content/context (meaning and correlation) </p>
                <p>• Community (sharing and collaboration) </p>
                <p>• Customization (personalization and value) </p>
                <p>&nbsp;</p>
                <p>&nbsp;</p>
            </div>
          </div>
        </div>
      </div>
    </main>
  </div>
  </div>
</body>

</html>