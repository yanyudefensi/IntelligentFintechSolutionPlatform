from scrapy.cmdline import execute
# execute(['scrapy', 'genspider', 'rgzn','ailab.cn'])
# execute(['scrapy', 'genspider', 'yjs2','searchcloudcomputing.techtarget.com.cn'])
# execute(['scrapy', 'genspider', 'yjs3','searchcloudcomputing.techtarget.com.cn'])
# execute(['scrapy', 'genspider', 'yjs4','searchcloudcomputing.techtarget.com.cn'])
# execute(['scrapy', 'genspider', 'baidu_qkl','baidu.com'])
# execute(['scrapy', 'genspider', 'baidu_wlw','baidu.com'])
# execute(['scrapy', 'genspider', 'baidu_rgzn','baidu.com'])
# execute(['scrapy', 'genspider', 'baidu_dsj','baidu.com'])
# execute(['scrapy', 'genspider', 'kjxw','tech.ailab.cn'])
# execute(['scrapy', 'genspider', 'csdn_wlw','blog.csdn.net'])
# execute(['scrapy', 'genspider', 'csdn_qkl','blog.csdn.net'])
# execute(['scrapy', 'genspider', 'csdn_dsj','blog.csdn.net'])
# execute(['scrapy', 'genspider', 'csdn_yjs','blog.csdn.net'])
# execute(['scrapy', 'genspider', 'csdn_rgzn','blog.csdn.net'])
# execute(['scrapy', 'genspider', 'babit','8btc.com'])
# execute(['scrapy', 'genspider', '360_wlw','btime.com'])
# execute(['scrapy', 'genspider', '360_qkl','btime.com'])
# execute(['scrapy', 'genspider', '360_dsj','btime.com'])
# execute(['scrapy', 'genspider', '360_yjs','btime.com'])
# execute(['scrapy', 'genspider', '360_rgzn','btime.com'])
# execute(['scrapy', 'genspider', 'segfault','segmentfault.com'])
# execute(['scrapy', 'genspider', 'tttbit','tttbit.com'])
# execute(['scrapy', 'genspider', 'tttbit_rgzn','tttbit.com'])
# execute(['scrapy', 'genspider', 'tttbit_qkl','tttbit.com'])
# execute(['scrapy', 'genspider', 'lsj','7234.cn'])#链世界
# execute(['scrapy', 'genspider', 'lsj_zx','7234.cn'])#链世界资讯
execute(['scrapy', 'genspider', 'bcfans','bcfans.com'])